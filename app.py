# app.py - Streamlitå‰ç«¯åº”ç”¨
# app.py - Streamlitå‰ç«¯åº”ç”¨
import streamlit as st
import asyncio
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent
sys.path.append(str(project_root))

# ä»…åŠ è½½é…ç½®ï¼Œä¸å†éœ€è¦åœ¨è¿™é‡Œç™»å½•
try:
    from configs.config import config
except ImportError as e:
    st.error(f"å¯¼å…¥é…ç½®å¤±è´¥: {e}")
    st.stop()

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
try:
    from src.generation.rag_generator import RAGSystem
    from src.retrieval.vector_database import VectorDatabaseManager
    from src.retrieval.reranker import AdvancedReranker
except ImportError as e:
    st.error(f"å¯¼å…¥æ¨¡å—å¤±è´¥: {e}")
    st.stop()

import streamlit as st
import asyncio
import time
import json
from pathlib import Path
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime
import sys
import os


# é¡µé¢é…ç½®
st.set_page_config(
    page_title="ğŸ¤– AIæŠ€æœ¯èµ„è®¯æ™ºèƒ½é—®ç­”ç³»ç»Ÿ",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
<style>
    .main {
        padding-top: 2rem;
    }
    
    .stAlert > div {
        padding-top: 1rem;
        padding-bottom: 1rem;
    }
    
    .chat-message {
        padding: 1rem;
        border-radius: 10px;
        margin-bottom: 1rem;
    }
    
    .user-message {
        background-color: #e3f2fd;
        border-left: 4px solid #1976d2;
    }
    
    .assistant-message {
        background-color: #f1f8e9;
        border-left: 4px solid #388e3c;
    }
    
    .source-card {
        background-color: #fafafa;
        padding: 1rem;
        border-radius: 8px;
        border-left: 3px solid #ff9800;
        margin-bottom: 0.5rem;
    }
    
    .metric-card {
        background-color: #fff3e0;
        padding: 1rem;
        border-radius: 8px;
        text-align: center;
    }
</style>
""", unsafe_allow_html=True)

@st.cache_resource
def initialize_rag_system():
    """åˆå§‹åŒ–RAGç³»ç»Ÿï¼ˆå¸¦ç¼“å­˜ï¼‰"""
    with st.spinner("ğŸ”„ æ­£åœ¨åˆå§‹åŒ–AIæ™ºèƒ½é—®ç­”ç³»ç»Ÿ..."):
        try:
            # é…ç½®
            rag_config = {
                'embedding_model': config.EMBEDDING_MODEL,
                'llm_model': config.LLM_MODEL,
                'device': config.DEVICE,
                'max_context_length': 3000,
                'qdrant_host': config.QDRANT_HOST,
                'qdrant_port': config.QDRANT_PORT,
                'collection_name': config.COLLECTION_NAME,
                'vector_size': 1024,
                'HUGGING_FACE_TOKEN': config.HUGGING_FACE_TOKEN # ä¿®æ”¹: å°†tokenæ·»åŠ åˆ°é…ç½®å­—å…¸
            }
            
            db_manager = VectorDatabaseManager(rag_config)
            
            reranker = None
            reranker_available = False
            try:
                reranker = AdvancedReranker()
                reranker_available = True
            except Exception as e:
                st.warning(f"é‡æ’åºå™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            
            # æ£€æŸ¥çŸ¥è¯†åº“çŠ¶æ€
            stats = db_manager.db.get_collection_stats()
            if stats.get('total_points', 0) == 0:
                st.error("âš ï¸ çŸ¥è¯†åº“ä¸ºç©ºï¼è¯·å…ˆè¿è¡Œæ•°æ®æ”¶é›†å’Œå¤„ç†è„šæœ¬ã€‚")
                return None, None, None
            
            # æ³¨å…¥ä¾èµ–é¡¹æ¥åˆå§‹åŒ–ä¸»ç³»ç»Ÿ
            rag_system = RAGSystem(config=rag_config, db_manager=db_manager, reranker=reranker)
            st.success(f"âœ… ç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ! çŸ¥è¯†åº“åŒ…å« {stats.get('total_points', 0)} ä¸ªæ–‡æ¡£ç‰‡æ®µã€‚")
            return rag_system, db_manager, reranker_available
            
        except Exception as e:
            # æ•è·å¹¶æ˜¾ç¤ºæ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
            st.error(f"âŒ ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {type(e).__name__}: {e}")
            return None, None, None


def render_chat_message(role: str, content: str, sources: list = None, metrics: dict = None):
    """æ¸²æŸ“èŠå¤©æ¶ˆæ¯"""
    
    if role == "user":
        st.markdown(f'''
        <div class="chat-message user-message">
            <strong>ğŸ¤” æ‚¨çš„é—®é¢˜:</strong><br>
            {content}
        </div>
        ''', unsafe_allow_html=True)
        
    else:  # assistant
        st.markdown(f'''
        <div class="chat-message assistant-message">
            <strong>ğŸ¤– AIå›ç­”:</strong><br>
            {content}
        </div>
        ''', unsafe_allow_html=True)
        
        # æ˜¾ç¤ºæŒ‡æ ‡
        if metrics:
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.markdown(f'''
                <div class="metric-card">
                    <strong>ç½®ä¿¡åº¦</strong><br>
                    <span style="color: #1976d2; font-size: 1.5em;">{metrics.get('confidence', 0):.2f}</span>
                </div>
                ''', unsafe_allow_html=True)
            
            with col2:
                st.markdown(f'''
                <div class="metric-card">
                    <strong>ç”Ÿæˆæ—¶é—´</strong><br>
                    <span style="color: #388e3c; font-size: 1.2em;">{metrics.get('generation_time', 0):.2f}s</span>
                </div>
                ''', unsafe_allow_html=True)
                
            with col3:
                st.markdown(f'''
                <div class="metric-card">
                    <strong>Tokenæ•°é‡</strong><br>
                    <span style="color: #f57c00; font-size: 1.2em;">{metrics.get('token_count', 0)}</span>
                </div>
                ''', unsafe_allow_html=True)
                
            with col4:
                st.markdown(f'''
                <div class="metric-card">
                    <strong>å‚è€ƒæºæ•°é‡</strong><br>
                    <span style="color: #7b1fa2; font-size: 1.2em;">{len(sources) if sources else 0}</span>
                </div>
                ''', unsafe_allow_html=True)
        
        # æ˜¾ç¤ºå‚è€ƒæ¥æº
        if sources:
            with st.expander(f"ğŸ“š å‚è€ƒæ¥æº ({len(sources)}ä¸ª)", expanded=False):
                for i, source in enumerate(sources, 1):
                    source_title = source.get('metadata', {}).get('title', f"æ¥æº {i}")
                    source_type = source.get('semantic_type', 'content')
                    scores = source.get('scores', {})
                    source_score = scores.get('rerank_score', scores.get('hybrid_score', 0.0))
                    
                    st.markdown(f'''
                    <div class="source-card">
                        <strong>ğŸ“„ {source_title[:80]}...</strong>
                        <span style="float: right; color: #666;">
                            [{source_type}] Score: {source_score:.3f}
                        </span><br>
                        <small style="color: #666;">
                            {source['content'][:200]}...
                        </small>
                    </div>
                    ''', unsafe_allow_html=True)

def render_knowledge_base_stats(db_manager):
    """æ¸²æŸ“çŸ¥è¯†åº“ç»Ÿè®¡ä¿¡æ¯"""
    
    try:
        stats = db_manager.db.get_collection_stats()
        
        st.markdown("### ğŸ“Š çŸ¥è¯†åº“ç»Ÿè®¡")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("æ€»æ–‡æ¡£ç‰‡æ®µ", stats.get('total_points', 0))
        
        with col2:
            st.metric("å‘é‡ç»´åº¦", stats.get('vector_size', 0))
            
        with col3:
            st.metric("è·ç¦»åº¦é‡", stats.get('distance_metric', 'N/A'))
        
        if st.checkbox("æ˜¾ç¤ºè¯¦ç»†ç»Ÿè®¡", key="show_detailed_stats"):
            sample_data = {
                'æ•°æ®æº': ['ArXivè®ºæ–‡', 'AIåšå®¢', 'Hugging Face', 'ä¼šè®®è®ºæ–‡'],
                'æ–‡æ¡£æ•°é‡': [450, 230, 180, 140],
            }
            df = pd.DataFrame(sample_data)
            fig = px.pie(df, values='æ–‡æ¡£æ•°é‡', names='æ•°æ®æº', title="æ•°æ®æºåˆ†å¸ƒ")
            st.plotly_chart(fig, use_container_width=True)
                
    except Exception as e:
        st.error(f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    
    st.title("ğŸ¤– AIæŠ€æœ¯èµ„è®¯æ™ºèƒ½é—®ç­”ç³»ç»Ÿ")
    st.markdown("""
    **åŸºäºRAGæŠ€æœ¯çš„æ™ºèƒ½AIèµ„è®¯åŠ©æ‰‹** å®æ—¶è·å–å’Œåˆ†ææœ€æ–°çš„AIè®ºæ–‡ã€æŠ€æœ¯åšå®¢å’Œå¼€æºé¡¹ç›®ï¼Œä¸ºæ‚¨æä¾›å‡†ç¡®ã€åŠæ—¶çš„æŠ€æœ¯è§£ç­”ã€‚
    """)
    
    with st.sidebar:
        st.header("âš™ï¸ ç³»ç»Ÿé…ç½®")
        st.subheader("ğŸ” æŸ¥è¯¢å‚æ•°")
        
        initial_retrieve = st.slider("åˆå§‹æ£€ç´¢æ•°é‡", 5, 30, 15, help="å¢åŠ æ•°é‡å¯æé«˜å¬å›ç‡ï¼Œä½†ä¼šå¢åŠ å¤„ç†æ—¶é—´")
        top_k = st.slider("æœ€ç»ˆç»“æœæ•°é‡", 3, 10, 5, help="ç»è¿‡MMRå¤šæ ·æ€§é€‰æ‹©åï¼Œè¿”å›ç»™ç”¨æˆ·çš„æœ€ç»ˆæ–‡æ¡£æ•°é‡")
        context_chunks = st.slider("ä¸Šä¸‹æ–‡ç‰‡æ®µæ•°é‡", 2, 5, 3, help="æä¾›ç»™æ¨¡å‹çš„ä¸Šä¸‹æ–‡ç‰‡æ®µæ•°é‡")
        
        with st.expander("ğŸ”§ é«˜çº§é€‰é¡¹"):
            enable_reranker = st.checkbox("å¯ç”¨é‡æ’åº", value=True, help="ä½¿ç”¨Advanced Rerankeræå‡æ£€ç´¢ç²¾åº¦å’Œå¤šæ ·æ€§")
            lambda_mult = st.slider("MMR å¤šæ ·æ€§ (Lambda)", 0.0, 1.0, 0.5, 0.1, help="æ§åˆ¶ç›¸å…³æ€§ä¸å¤šæ ·æ€§çš„å¹³è¡¡ã€‚1.0å®Œå…¨ç›¸å…³ï¼Œ0.0å®Œå…¨å¤šæ ·ã€‚")
            show_debug_info = st.checkbox("æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯", value=False)
            temperature = st.slider("ç”Ÿæˆæ¸©åº¦", 0.0, 1.0, 0.1, 0.1, help="æ§åˆ¶ç”Ÿæˆçš„éšæœºæ€§")
    
    if 'rag_system' not in st.session_state:
        rag_system, db_manager, reranker_available = initialize_rag_system()
        if rag_system is None:
            st.stop()
        st.session_state.rag_system = rag_system
        st.session_state.db_manager = db_manager
        st.session_state.reranker_available = reranker_available
        st.session_state.chat_history = []
    
    tab1, tab2, tab3 = st.tabs(["ğŸ’¬ æ™ºèƒ½é—®ç­”", "ğŸ“Š çŸ¥è¯†åº“æ¦‚è§ˆ", "â„¹ï¸ ç³»ç»Ÿä¿¡æ¯"])
    
    with tab1:
        st.markdown("### ğŸ’¬ ä¸AIåŠ©æ‰‹å¯¹è¯")
        
        for message in st.session_state.chat_history:
            render_chat_message(role=message['role'], content=message['content'], sources=message.get('sources'), metrics=message.get('metrics'))
        
        user_query = st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜ï¼ˆæ”¯æŒä¸­è‹±æ–‡ï¼‰:")
        
        if user_query:
            st.session_state.chat_history.append({'role': 'user', 'content': user_query})
            with st.chat_message("user"):
                st.markdown(user_query)
            
            with st.chat_message("assistant"):
                message_placeholder = st.empty()
                with st.spinner("ğŸ¤” AIæ­£åœ¨æ€è€ƒä¸­..."):
                    try:
                        loop = asyncio.new_event_loop()
                        asyncio.set_event_loop(loop)
                        
                        query_params = {
                            'initial_retrieve': initial_retrieve,
                            'top_k': top_k,
                            'context_chunks': context_chunks,
                            'lambda_mult': lambda_mult,
                            'use_reranker': enable_reranker and st.session_state.reranker_available
                        }
                        
                        result = loop.run_until_complete(
                            st.session_state.rag_system.generate_answer(user_query, **query_params)
                        )
                        
                        metrics = {'confidence': result.confidence, 'generation_time': result.generation_time, 'token_count': result.token_count}
                        render_chat_message("assistant", result.answer, sources=result.source_chunks, metrics=metrics)
                        
                        st.session_state.chat_history.append({'role': 'assistant', 'content': result.answer, 'sources': result.source_chunks, 'metrics': metrics})

                        if show_debug_info:
                            with st.expander("ğŸ” è°ƒè¯•ä¿¡æ¯"):
                                st.json({'params': query_params})
                        
                    except Exception as e:
                        st.error(f"âŒ ç”Ÿæˆå›ç­”æ—¶å‡ºé”™: {e}")
                    finally:
                        loop.close()
    
    with tab2:
        render_knowledge_base_stats(st.session_state.db_manager)
        st.markdown("### ğŸ’¡ ç¤ºä¾‹æŸ¥è¯¢")
        example_queries = ["ä»€ä¹ˆæ˜¯Transformeræ¶æ„çš„æ ¸å¿ƒåˆ›æ–°ï¼Ÿ", "å¦‚ä½•æé«˜å¤§è¯­è¨€æ¨¡å‹çš„æ•ˆç‡ï¼Ÿ", "RAGæŠ€æœ¯æœ‰ä»€ä¹ˆä¼˜åŠ¿å’Œå±€é™æ€§ï¼Ÿ"]
        for query in example_queries:
            if st.button(f"ğŸ“ {query}"):
                st.session_state.user_input = query
                st.rerun()
    
    with tab3:
        st.markdown("### â„¹ï¸ ç³»ç»Ÿæ¶æ„ä¿¡æ¯")
        system_info = {
            "ğŸ” æ£€ç´¢æ¨¡å‹": "BAAI/bge-m3", "ğŸ§  ç”Ÿæˆæ¨¡å‹": "Qwen2-7B-Instruct", "ğŸ—„ï¸ å‘é‡æ•°æ®åº“": "Qdrant",
            "ğŸ”„ é‡æ’åºå™¨": "BAAI/bge-reranker-base + MMR", "ğŸŒ å‰ç«¯æ¡†æ¶": "Streamlit",
        }
        for component, description in system_info.items():
            st.markdown(f"**{component}**: {description}")

if __name__ == "__main__":
    main()

