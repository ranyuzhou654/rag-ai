# src/generation/ultimate_rag_system.py
from typing import List, Dict, Optional, Tuple, Any
import asyncio
import time
import uuid
from dataclasses import dataclass
from loguru import logger

from src.retrieval.vector_database import VectorDatabaseManager
from src.retrieval.reranker import AdvancedReranker
from src.retrieval.query_intelligence import QueryIntelligenceEngine
from src.retrieval.agentic_rag import AgenticRAGOrchestrator, AgenticStep
from src.retrieval.contextual_compression import ContextualCompressor, SmartReranker
from src.knowledge_graph import KnowledgeGraphIndexer, KnowledgeGraphRetriever, KGEnhancedRetriever
from src.generation.tiered_generation import TieredGenerationSystem, TaskRequest, TaskType, TaskComplexity
from src.feedback import FeedbackCollector
from .rag_generator import GenerationResult, EnhancedContextOptimizer

@dataclass
class UltimateGenerationResult:
    """ç»ˆæRAGç³»ç»Ÿç”Ÿæˆç»“æœ"""
    answer: str
    source_chunks: List[Dict]
    confidence: float
    generation_time: float
    token_count: int
    
    # æŸ¥è¯¢æ™ºèƒ½ä¿¡æ¯
    query_analysis: Optional[Dict] = None
    optimized_queries: Optional[List[str]] = None
    hyde_document: Optional[str] = None
    
    # æ£€ç´¢ç­–ç•¥ä¿¡æ¯
    retrieval_strategies: Optional[List[str]] = None
    agentic_steps: Optional[List[AgenticStep]] = None
    iterations_used: Optional[int] = None
    
    # çŸ¥è¯†å›¾è°±ä¿¡æ¯
    kg_entities: Optional[List[str]] = None
    kg_relations: Optional[List[Dict]] = None
    kg_enhanced_chunks: Optional[int] = None
    
    # åˆ†å±‚ç”Ÿæˆä¿¡æ¯
    models_used: Optional[Dict[str, float]] = None
    task_breakdown: Optional[List[Dict]] = None
    total_cost: Optional[float] = None
    
    # æ€§èƒ½æŒ‡æ ‡
    retrieval_precision: Optional[float] = None
    context_compression_ratio: Optional[float] = None
    system_version: str = "Ultimate-RAG-v1.0"

class UltimateRAGSystem:
    """ç»ˆæRAGç³»ç»Ÿ - é›†æˆæ‰€æœ‰å…ˆè¿›åŠŸèƒ½"""
    
    def __init__(self, config: Dict):
        self.config = config
        self.system_id = str(uuid.uuid4())[:8]
        
        logger.info(f"ğŸš€ Initializing Ultimate RAG System [{self.system_id}]...")
        
        # 1. åˆå§‹åŒ–æ ¸å¿ƒç»„ä»¶
        self.db_manager = VectorDatabaseManager(config)
        self.reranker = AdvancedReranker() if config.get('use_reranker', True) else None
        
        # 2. åˆå§‹åŒ–æŸ¥è¯¢æ™ºèƒ½
        self.query_intelligence = QueryIntelligenceEngine(config)
        
        # 3. åˆå§‹åŒ–çŸ¥è¯†å›¾è°±ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        self.kg_enabled = config.get('enable_knowledge_graph', False)
        if self.kg_enabled:
            try:
                self.kg_indexer = KnowledgeGraphIndexer(config)
                self.kg_retriever = KnowledgeGraphRetriever(config)
                self.kg_enhanced_retriever = KGEnhancedRetriever(
                    self.db_manager, self.kg_retriever
                )
                logger.info("âœ… Knowledge Graph components initialized")
            except Exception as e:
                logger.error(f"âŒ Knowledge Graph initialization failed: {e}")
                self.kg_enabled = False
        
        # 4. åˆå§‹åŒ–ä¸Šä¸‹æ–‡ä¼˜åŒ–å™¨
        self.context_optimizer = EnhancedContextOptimizer(
            max_context_length=config.get('max_context_length', 3000),
            config=config
        )
        
        # 5. åˆå§‹åŒ–åˆ†å±‚ç”Ÿæˆç³»ç»Ÿ
        self.tiered_generation_enabled = config.get('enable_tiered_generation', False)
        if self.tiered_generation_enabled:
            try:
                self.tiered_generator = TieredGenerationSystem(config)
                logger.info("âœ… Tiered Generation System initialized")
            except Exception as e:
                logger.error(f"âŒ Tiered Generation initialization failed: {e}")
                self.tiered_generation_enabled = False
        
        # 6. åˆå§‹åŒ–æ™ºèƒ½ä½“RAG
        self.agentic_orchestrator = AgenticRAGOrchestrator(
            db_manager=self.db_manager,
            query_processor=None,  # å°†åœ¨ä¸‹é¢è®¾ç½®
            context_optimizer=self.context_optimizer,
            llm_generator=None,  # ä½¿ç”¨åˆ†å±‚ç”Ÿæˆç³»ç»Ÿ
            config=config
        )
        
        # 7. åˆå§‹åŒ–åé¦ˆæ”¶é›†å™¨
        self.feedback_enabled = config.get('enable_feedback_collection', False)
        if self.feedback_enabled:
            feedback_db_path = config.get('feedback_db_path', 'data/feedback/feedback.db')
            self.feedback_collector = FeedbackCollector(feedback_db_path)
        
        # ç³»ç»Ÿç»Ÿè®¡
        self.stats = {
            'total_queries': 0,
            'successful_queries': 0,
            'avg_response_time': 0.0,
            'total_cost': 0.0,
            'kg_enhanced_queries': 0,
            'agentic_queries': 0,
            'tiered_generation_usage': {}
        }
        
        logger.success(f"ğŸ‰ Ultimate RAG System [{self.system_id}] initialized successfully!")
        self._log_system_capabilities()
    
    def _log_system_capabilities(self):
        """è®°å½•ç³»ç»Ÿèƒ½åŠ›"""
        capabilities = [
            "âœ“ Query Intelligence (rewriting, sub-questions, HyDE)",
            "âœ“ Multi-representation Indexing",
            "âœ“ Agentic RAG (retrieval-evaluation-correction loop)",
            "âœ“ Contextual Compression & Smart Reranking"
        ]
        
        if self.kg_enabled:
            capabilities.append("âœ“ Knowledge Graph Indexing & Retrieval")
        if self.tiered_generation_enabled:
            capabilities.append("âœ“ Tiered Generation with Task Routing")
        if self.feedback_enabled:
            capabilities.append("âœ“ Human-in-the-loop Feedback System")
        
        logger.info("ğŸ”§ System Capabilities:")
        for cap in capabilities:
            logger.info(f"   {cap}")
    
    async def generate_answer(
        self, 
        user_query: str, 
        mode: str = "ultimate",  # "basic", "enhanced", "agentic", "ultimate"
        **kwargs
    ) -> UltimateGenerationResult:
        """ç”Ÿæˆç­”æ¡ˆ - æ”¯æŒå¤šç§æ¨¡å¼"""
        
        start_time = time.time()
        session_id = str(uuid.uuid4())[:8]
        
        logger.info(f"ğŸ” Query [{session_id}]: {user_query[:100]}...")
        logger.info(f"ğŸ¯ Mode: {mode}")
        
        # æ›´æ–°ç»Ÿè®¡
        self.stats['total_queries'] += 1
        
        try:
            if mode == "basic":
                result = await self._basic_generation(user_query, session_id, **kwargs)
            elif mode == "enhanced":
                result = await self._enhanced_generation(user_query, session_id, **kwargs)
            elif mode == "agentic":
                result = await self._agentic_generation(user_query, session_id, **kwargs)
            elif mode == "ultimate":
                result = await self._ultimate_generation(user_query, session_id, **kwargs)
            else:
                raise ValueError(f"Unknown mode: {mode}")
            
            # æ›´æ–°ç»Ÿè®¡
            self.stats['successful_queries'] += 1
            self._update_stats(result)
            
            logger.success(f"âœ… Query [{session_id}] completed in {result.generation_time:.2f}s")
            return result
            
        except Exception as e:
            logger.error(f"âŒ Query [{session_id}] failed: {e}")
            
            # è¿”å›é”™è¯¯ç»“æœ
            return UltimateGenerationResult(
                answer=f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„æŸ¥è¯¢æ—¶é‡åˆ°é”™è¯¯ï¼š{str(e)}",
                source_chunks=[],
                confidence=0.0,
                generation_time=time.time() - start_time,
                token_count=0,
                system_version="Ultimate-RAG-v1.0"
            )
    
    async def _basic_generation(
        self, 
        query: str, 
        session_id: str, 
        **kwargs
    ) -> UltimateGenerationResult:
        """åŸºç¡€ç”Ÿæˆæ¨¡å¼"""
        
        # ç®€å•å‘é‡æ£€ç´¢
        query_vector = self.query_intelligence.embedder.encode([query], convert_to_numpy=True)[0]
        chunks = self.db_manager.search(
            query_vector=query_vector,
            query_text=query,
            top_k=kwargs.get('top_k', 5)
        )
        
        # åŸºç¡€ä¸Šä¸‹æ–‡ä¼˜åŒ–
        context, final_chunks = self.context_optimizer.optimize_context(
            chunks, top_k=kwargs.get('context_chunks', 3)
        )
        
        # ä½¿ç”¨åˆ†å±‚ç”Ÿæˆæˆ–å›é€€åˆ°åŸºç¡€ç”Ÿæˆ
        if self.tiered_generation_enabled:
            answer, models_used, cost = await self._generate_with_tiered_system(
                query, context, TaskComplexity.SIMPLE
            )
        else:
            answer = f"åŸºäºæ£€ç´¢åˆ°çš„ä¿¡æ¯ï¼š{context[:500]}...\n\nå›ç­”ï¼šè¿™æ˜¯ä¸€ä¸ªåŸºç¡€å›ç­”æ¨¡å¼çš„ç¤ºä¾‹ã€‚"
            models_used = {"basic_fallback": 0.1}
            cost = 0.0
        
        return UltimateGenerationResult(
            answer=answer,
            source_chunks=final_chunks,
            confidence=0.6,
            generation_time=time.time() - self.stats.get('_start_time', time.time()),
            token_count=len(answer.split()),
            retrieval_strategies=["vector_search"],
            models_used=models_used,
            total_cost=cost
        )
    
    async def _enhanced_generation(
        self, 
        query: str, 
        session_id: str, 
        **kwargs
    ) -> UltimateGenerationResult:
        """å¢å¼ºç”Ÿæˆæ¨¡å¼"""
        
        # 1. æŸ¥è¯¢æ™ºèƒ½å¤„ç†
        analysis = self.query_intelligence.analyze_query(query)
        optimized_queries = self.query_intelligence.get_optimized_queries(query)
        hyde_doc = self.query_intelligence.get_hyde_document(query)
        
        # 2. å¤šç­–ç•¥æ£€ç´¢
        all_chunks = []
        retrieval_strategies = []
        
        # å‘é‡æ£€ç´¢
        for opt_query in optimized_queries[:3]:
            query_vector = self.query_intelligence.embedder.encode([opt_query], convert_to_numpy=True)[0]
            chunks = self.db_manager.search(query_vector=query_vector, query_text=opt_query, top_k=5)
            all_chunks.extend(chunks)
            retrieval_strategies.append(f"vector_query_{len(retrieval_strategies)}")
        
        # HyDEæ£€ç´¢
        if hyde_doc:
            hyde_vector = self.query_intelligence.embedder.encode([hyde_doc], convert_to_numpy=True)[0]
            hyde_chunks = self.db_manager.search(query_vector=hyde_vector, query_text=hyde_doc, top_k=5)
            all_chunks.extend(hyde_chunks)
            retrieval_strategies.append("hyde")
        
        # çŸ¥è¯†å›¾è°±å¢å¼ºï¼ˆå¦‚æœå¯ç”¨ï¼‰
        kg_entities = []
        kg_relations = []
        kg_enhanced_count = 0
        
        if self.kg_enabled:
            all_chunks = self.kg_retriever.enhance_chunks_with_kg(query, all_chunks)
            kg_enhanced_count = sum(1 for c in all_chunks if c.get('has_kg_enhancement', False))
            retrieval_strategies.append("kg_enhanced")
            
            # æå–KGä¿¡æ¯
            kg_results = self.kg_retriever.retrieve_kg_context(query)
            kg_entities = [r.entity for r in kg_results if r.source_type == 'entity']
            kg_relations = [
                {'source': r.metadata.get('source_entity'), 'relation': r.metadata.get('relation_type'), 'target': r.entity}
                for r in kg_results if r.source_type == 'relation'
            ]
        
        # 3. å»é‡å’Œé‡æ’åº
        unique_chunks = self._deduplicate_chunks(all_chunks)
        
        # 4. æ™ºèƒ½ä¸Šä¸‹æ–‡ä¼˜åŒ–
        context, final_chunks = self.context_optimizer.optimize_context(
            unique_chunks,
            top_k=kwargs.get('context_chunks', 5),
            query=query,
            use_compression=kwargs.get('use_compression', True)
        )
        
        # 5. åˆ†å±‚ç”Ÿæˆ
        if self.tiered_generation_enabled:
            complexity = self._determine_task_complexity(query, analysis)
            answer, models_used, cost = await self._generate_with_tiered_system(
                query, context, complexity
            )
        else:
            answer = f"å¢å¼ºæ¨¡å¼å›ç­”åŸºäºå¤šç­–ç•¥æ£€ç´¢å’Œæ™ºèƒ½å¤„ç†ï¼š\n\n{context[:800]}"
            models_used = {"enhanced_fallback": 0.2}
            cost = 0.0
        
        return UltimateGenerationResult(
            answer=answer,
            source_chunks=final_chunks,
            confidence=self._calculate_enhanced_confidence(final_chunks, analysis),
            generation_time=time.time() - self.stats.get('_start_time', time.time()),
            token_count=len(answer.split()),
            query_analysis=analysis.__dict__ if hasattr(analysis, '__dict__') else None,
            optimized_queries=optimized_queries,
            hyde_document=hyde_doc,
            retrieval_strategies=retrieval_strategies,
            kg_entities=kg_entities,
            kg_relations=kg_relations,
            kg_enhanced_chunks=kg_enhanced_count,
            models_used=models_used,
            total_cost=cost
        )
    
    async def _agentic_generation(
        self, 
        query: str, 
        session_id: str, 
        **kwargs
    ) -> UltimateGenerationResult:
        """æ™ºèƒ½ä½“ç”Ÿæˆæ¨¡å¼"""
        
        self.stats['agentic_queries'] += 1
        
        # ä½¿ç”¨æ™ºèƒ½ä½“RAGç³»ç»Ÿ
        answer, final_chunks, agentic_steps, confidence = await self.agentic_orchestrator.agentic_retrieve_and_generate(
            query, **kwargs
        )
        
        # åˆ†ææ™ºèƒ½ä½“æ­¥éª¤
        retrieval_strategies = ["agentic"]
        models_used = {}
        total_cost = 0.0
        
        for step in agentic_steps:
            if hasattr(step, 'evaluation') and hasattr(step.evaluation, 'reasoning'):
                models_used[f"evaluator_step_{step.step_number}"] = 0.1
                total_cost += 0.001  # ä¼°ç®—æˆæœ¬
        
        return UltimateGenerationResult(
            answer=answer,
            source_chunks=final_chunks,
            confidence=confidence,
            generation_time=time.time() - self.stats.get('_start_time', time.time()),
            token_count=len(answer.split()),
            retrieval_strategies=retrieval_strategies,
            agentic_steps=agentic_steps,
            iterations_used=len(agentic_steps),
            models_used=models_used,
            total_cost=total_cost
        )
    
    async def _ultimate_generation(
        self, 
        query: str, 
        session_id: str, 
        **kwargs
    ) -> UltimateGenerationResult:
        """ç»ˆæç”Ÿæˆæ¨¡å¼ - é›†æˆæ‰€æœ‰åŠŸèƒ½"""
        
        # 1. æŸ¥è¯¢æ™ºèƒ½åˆ†æ
        analysis = self.query_intelligence.analyze_query(query)
        complexity = self._determine_task_complexity(query, analysis)
        
        logger.info(f"ğŸ“Š Query Analysis: complexity={complexity.value}, type={analysis.query_type}")
        
        # 2. é€‰æ‹©æœ€ä½³ç­–ç•¥
        if complexity in [TaskComplexity.COMPLEX, TaskComplexity.CRITICAL] and len(analysis.sub_questions) > 1:
            # å¤æ‚æŸ¥è¯¢ä½¿ç”¨æ™ºèƒ½ä½“æ¨¡å¼
            logger.info("ğŸ¤– Using Agentic RAG for complex query")
            return await self._agentic_generation(query, session_id, **kwargs)
        else:
            # ä¸­ç­‰å¤æ‚åº¦ä½¿ç”¨å¢å¼ºæ¨¡å¼ + é¢å¤–ä¼˜åŒ–
            logger.info("âš¡ Using Ultimate Enhanced mode")
            
            # åŸºäºå¢å¼ºæ¨¡å¼ï¼Œå¢åŠ é¢å¤–çš„ä¼˜åŒ–
            enhanced_result = await self._enhanced_generation(query, session_id, **kwargs)
            
            # Ultimateæ¨¡å¼çš„é¢å¤–å¤„ç†
            if self.kg_enabled and enhanced_result.kg_enhanced_chunks == 0:
                # å¦‚æœæ²¡æœ‰KGå¢å¼ºï¼Œå°è¯•æ›´æ·±åº¦çš„KGæ£€ç´¢
                logger.info("ğŸ” Attempting deeper KG retrieval")
                deeper_kg = await self._deep_kg_analysis(query)
                if deeper_kg:
                    enhanced_result.kg_entities = deeper_kg.get('entities', [])
                    enhanced_result.kg_relations = deeper_kg.get('relations', [])
            
            # è´¨é‡éªŒè¯å’Œç½®ä¿¡åº¦è°ƒæ•´
            enhanced_result.confidence = self._calculate_ultimate_confidence(enhanced_result)
            
            # æ·»åŠ ç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡
            enhanced_result.retrieval_precision = self._calculate_retrieval_precision(enhanced_result.source_chunks)
            enhanced_result.context_compression_ratio = self._calculate_compression_ratio(enhanced_result.source_chunks)
            
            return enhanced_result
    
    async def _generate_with_tiered_system(
        self, 
        query: str, 
        context: str, 
        complexity: TaskComplexity
    ) -> Tuple[str, Dict[str, float], float]:
        """ä½¿ç”¨åˆ†å±‚ç”Ÿæˆç³»ç»Ÿç”Ÿæˆç­”æ¡ˆ"""
        
        if not self.tiered_generation_enabled:
            return f"åŸºäºä¸Šä¸‹æ–‡çš„å›ç­”ï¼š{context[:500]}...", {"fallback": 0.1}, 0.0
        
        # åˆ›å»ºç”Ÿæˆä»»åŠ¡
        task = TaskRequest(
            task_id=str(uuid.uuid4())[:8],
            task_type=TaskType.FINAL_GENERATION,
            complexity=complexity,
            prompt=f"åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ã€‚\n\nä¸Šä¸‹æ–‡ï¼š{context}\n\né—®é¢˜ï¼š{query}\n\nç­”æ¡ˆï¼š",
            context={"query": query, "context": context},
            max_tokens=1024,
            priority=3 if complexity in [TaskComplexity.COMPLEX, TaskComplexity.CRITICAL] else 1
        )
        
        # æ‰§è¡Œä»»åŠ¡
        response = await self.tiered_generator.execute_task(task)
        
        models_used = {response.model_used: response.execution_time}
        total_cost = response.cost
        
        return response.result, models_used, total_cost
    
    def _determine_task_complexity(self, query: str, analysis) -> TaskComplexity:
        """ç¡®å®šä»»åŠ¡å¤æ‚åº¦"""
        if hasattr(analysis, 'complexity'):
            complexity_map = {
                'simple': TaskComplexity.SIMPLE,
                'medium': TaskComplexity.MEDIUM,
                'complex': TaskComplexity.COMPLEX
            }
            return complexity_map.get(analysis.complexity, TaskComplexity.MEDIUM)
        
        # åŸºäºæŸ¥è¯¢é•¿åº¦çš„ç®€å•åˆ¤æ–­
        if len(query.split()) < 5:
            return TaskComplexity.SIMPLE
        elif len(query.split()) < 15:
            return TaskComplexity.MEDIUM
        else:
            return TaskComplexity.COMPLEX
    
    async def _deep_kg_analysis(self, query: str) -> Optional[Dict]:
        """æ·±åº¦çŸ¥è¯†å›¾è°±åˆ†æ"""
        if not self.kg_enabled:
            return None
        
        try:
            # è·å–å®ä½“é‚»åŸŸä¿¡æ¯
            kg_results = self.kg_retriever.retrieve_kg_context(query, top_k=20)
            
            entities = []
            relations = []
            
            for result in kg_results:
                if result.source_type == 'entity':
                    entities.append(result.entity)
                elif result.source_type == 'relation':
                    relations.append({
                        'source': result.metadata.get('source_entity'),
                        'relation': result.metadata.get('relation_type'),
                        'target': result.entity
                    })
            
            return {'entities': entities, 'relations': relations}
            
        except Exception as e:
            logger.error(f"Deep KG analysis failed: {e}")
            return None
    
    def _deduplicate_chunks(self, chunks: List[Dict]) -> List[Dict]:
        """å»é‡æ–‡æ¡£å—"""
        if not chunks:
            return []
        
        unique_chunks = []
        seen_contents = set()
        
        for chunk in chunks:
            content_hash = hash(chunk['content'][:200])
            if content_hash not in seen_contents:
                seen_contents.add(content_hash)
                unique_chunks.append(chunk)
        
        return unique_chunks
    
    def _calculate_enhanced_confidence(self, chunks: List[Dict], analysis) -> float:
        """è®¡ç®—å¢å¼ºç½®ä¿¡åº¦"""
        base_confidence = 0.5
        
        # åŸºäºæ£€ç´¢ç»“æœæ•°é‡
        if chunks:
            base_confidence += min(len(chunks) * 0.1, 0.3)
        
        # åŸºäºæŸ¥è¯¢å¤æ‚åº¦åŒ¹é…
        if hasattr(analysis, 'complexity'):
            if analysis.complexity == 'simple':
                base_confidence += 0.1
        
        # åŸºäºçŸ¥è¯†å›¾è°±å¢å¼º
        kg_enhanced = sum(1 for c in chunks if c.get('has_kg_enhancement', False))
        if kg_enhanced > 0:
            base_confidence += min(kg_enhanced * 0.05, 0.15)
        
        return min(base_confidence, 1.0)
    
    def _calculate_ultimate_confidence(self, result: UltimateGenerationResult) -> float:
        """è®¡ç®—ç»ˆæç½®ä¿¡åº¦"""
        confidence = result.confidence
        
        # KGå¢å¼ºåŠ åˆ†
        if result.kg_entities:
            confidence += len(result.kg_entities) * 0.02
        
        # å¤šç­–ç•¥æ£€ç´¢åŠ åˆ†
        if result.retrieval_strategies and len(result.retrieval_strategies) > 1:
            confidence += 0.05
        
        # æ™ºèƒ½ä½“è¿­ä»£åŠ åˆ†
        if result.iterations_used and result.iterations_used > 1:
            confidence += 0.1
        
        return min(confidence, 1.0)
    
    def _calculate_retrieval_precision(self, chunks: List[Dict]) -> float:
        """è®¡ç®—æ£€ç´¢ç²¾ç¡®åº¦"""
        if not chunks:
            return 0.0
        
        # åŸºäºåˆ†æ•°åˆ†å¸ƒçš„ç®€å•ç²¾ç¡®åº¦ä¼°ç®—
        scores = []
        for chunk in chunks:
            chunk_scores = chunk.get('scores', {})
            if 'hybrid_score' in chunk_scores:
                scores.append(chunk_scores['hybrid_score'])
            elif 'vector_score' in chunk_scores:
                scores.append(chunk_scores['vector_score'])
        
        if scores:
            return sum(scores) / len(scores)
        
        return 0.5  # é»˜è®¤å€¼
    
    def _calculate_compression_ratio(self, chunks: List[Dict]) -> float:
        """è®¡ç®—å‹ç¼©æ¯”"""
        if not chunks:
            return 1.0
        
        # ç®€å•ä¼°ç®—ï¼šåŸºäºå—æ•°é‡çš„å‹ç¼©æ•ˆæœ
        original_count = len(chunks) * 500  # å‡è®¾æ¯å—500å­—ç¬¦
        compressed_count = sum(len(chunk.get('content', '')) for chunk in chunks[:3])  # å®é™…ä½¿ç”¨çš„å‰3å—
        
        if original_count > 0:
            return compressed_count / original_count
        
        return 1.0
    
    def _update_stats(self, result: UltimateGenerationResult):
        """æ›´æ–°ç³»ç»Ÿç»Ÿè®¡"""
        # æ›´æ–°å¹³å‡å“åº”æ—¶é—´
        total_time = self.stats['avg_response_time'] * (self.stats['total_queries'] - 1)
        self.stats['avg_response_time'] = (total_time + result.generation_time) / self.stats['total_queries']
        
        # æ›´æ–°æˆæœ¬
        if result.total_cost:
            self.stats['total_cost'] += result.total_cost
        
        # æ›´æ–°KGä½¿ç”¨ç»Ÿè®¡
        if result.kg_enhanced_chunks and result.kg_enhanced_chunks > 0:
            self.stats['kg_enhanced_queries'] += 1
        
        # æ›´æ–°åˆ†å±‚ç”Ÿæˆä½¿ç”¨ç»Ÿè®¡
        if result.models_used:
            for model_name in result.models_used:
                if model_name not in self.stats['tiered_generation_usage']:
                    self.stats['tiered_generation_usage'][model_name] = 0
                self.stats['tiered_generation_usage'][model_name] += 1
    
    def get_system_status(self) -> Dict[str, Any]:
        """è·å–ç³»ç»ŸçŠ¶æ€"""
        return {
            'system_id': self.system_id,
            'version': 'Ultimate-RAG-v1.0',
            'capabilities': {
                'query_intelligence': True,
                'knowledge_graph': self.kg_enabled,
                'tiered_generation': self.tiered_generation_enabled,
                'agentic_rag': True,
                'feedback_collection': self.feedback_enabled
            },
            'statistics': self.stats.copy(),
            'performance': {
                'success_rate': self.stats['successful_queries'] / max(self.stats['total_queries'], 1),
                'avg_response_time': self.stats['avg_response_time'],
                'total_cost': self.stats['total_cost']
            }
        }
    
    async def collect_feedback(
        self, 
        query: str, 
        result: UltimateGenerationResult, 
        is_positive: bool,
        comment: Optional[str] = None
    ) -> Optional[str]:
        """æ”¶é›†ç”¨æˆ·åé¦ˆ"""
        if not self.feedback_enabled:
            return None
        
        feedback_id = self.feedback_collector.collect_thumbs_feedback(
            query=query,
            answer=result.answer,
            is_positive=is_positive,
            source_chunks=result.source_chunks,
            generation_result={
                'query_analysis': result.query_analysis,
                'retrieval_strategies': result.retrieval_strategies,
                'generation_time': result.generation_time,
                'confidence': result.confidence,
                'models_used': result.models_used,
                'total_cost': result.total_cost
            }
        )
        
        logger.info(f"ğŸ“ Feedback collected: {feedback_id} ({'positive' if is_positive else 'negative'})")
        return feedback_id

# ä½¿ç”¨ç¤ºä¾‹
async def main():
    """æµ‹è¯•ç»ˆæRAGç³»ç»Ÿ"""
    config = {
        'llm_model': 'Qwen/Qwen2-7B-Instruct',
        'embedding_model': 'BAAI/bge-m3',
        'device': 'auto',
        'HUGGING_FACE_TOKEN': None,
        
        # åŠŸèƒ½å¼€å…³
        'enable_knowledge_graph': True,
        'enable_tiered_generation': True,
        'enable_feedback_collection': True,
        
        # è·¯å¾„é…ç½®
        'knowledge_graph_db_path': 'data/knowledge_graph/kg.db',
        'feedback_db_path': 'data/feedback/feedback.db',
        
        # APIæ¨¡å‹é…ç½®ï¼ˆå¯é€‰ï¼‰
        'api_models': {
            # 'gpt4_api_key': 'your-key-here'
        }
    }
    
    # åˆå§‹åŒ–ç³»ç»Ÿ
    ultimate_rag = UltimateRAGSystem(config)
    
    # æµ‹è¯•ä¸åŒæ¨¡å¼
    test_queries = [
        ("ä»€ä¹ˆæ˜¯Transformeræ¨¡å‹ï¼Ÿ", "basic"),
        ("è¯·è¯¦ç»†æ¯”è¾ƒBERTå’ŒGPTæ¨¡å‹çš„å¼‚åŒç‚¹", "enhanced"), 
        ("åˆ†ææ·±åº¦å­¦ä¹ åœ¨è®¡ç®—æœºè§†è§‰å’Œè‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„ä¸åŒåº”ç”¨åŠå…¶æŠ€æœ¯æŒ‘æˆ˜", "ultimate")
    ]
    
    for query, mode in test_queries:
        print(f"\n{'='*80}")
        print(f"Query: {query}")
        print(f"Mode: {mode}")
        print('='*80)
        
        result = await ultimate_rag.generate_answer(query, mode=mode)
        
        print(f"Answer: {result.answer[:200]}...")
        print(f"Confidence: {result.confidence:.3f}")
        print(f"Generation Time: {result.generation_time:.2f}s")
        print(f"Retrieval Strategies: {result.retrieval_strategies}")
        print(f"Models Used: {result.models_used}")
        
        if result.kg_entities:
            print(f"KG Entities: {result.kg_entities[:5]}")
        
        if result.total_cost:
            print(f"Cost: ${result.total_cost:.4f}")
    
    # ç³»ç»ŸçŠ¶æ€
    status = ultimate_rag.get_system_status()
    print(f"\nğŸ“Š System Status:")
    print(f"Success Rate: {status['performance']['success_rate']:.3f}")
    print(f"Avg Response Time: {status['performance']['avg_response_time']:.2f}s")
    print(f"Total Queries: {status['statistics']['total_queries']}")

if __name__ == "__main__":
    asyncio.run(main())